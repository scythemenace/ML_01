
## Linear Regression Model
In the **`supandunsupML`** markdown file, we talked about the regression and classification model. In the regression model, there is something called the **Linear Regression Model** which may be used for predicting data based on data we already have.

Suppose we had a graph denoting prices of houses based on their size (**note this is a supervised model because the output has a label which is basically price of the house**)

![House-size-price data comparison](./related%20images/Screenshot%202023-03-11%20at%201.06.02%20AM.png)

In the above image we can see multiple data coordinates we have. The **goal of linear regression** is to draw the best fitting straight **line** that describes the relation between the two variables (size and price). It is a regression model because the output(price) is numbers unlike classification where we have discrete structures as output.

`We can also represent the above data in the image using a table`

| <h5 style="color: blue;">size in feet<sup>2</sup></h5> | <h5 style="color: blue;">price in $1000's</h5> |
|--------------------------------------------------------|------------------------------------------------|
| 2104                                                   | 400                                            |
| 1416                                                   | 232                                            |
| 1534                                                   | 315                                            |
| 852                                                    | 178                                            |
| ...                                                    | ...                                            |
| 3210                                                   | 870                                            |

The above table is what we call a '**training set**'. It is basically a subset of a dataset used to train a model. By '**training**' a model we refer to process of teaching an algorithm to make accurate decisions based on by adjusting its parameters to the relationships found in the training set.

the input here (x-coordinate i.e. the size in feet<sup>2</sup>) is called the '**feature**' and the output (y-coordinate i.e. price in $1000's) is called the '**target**'.

(x<sup>n,</sup>, y<sup>n</sup>) is known for denoting a specific training example at the n<sup>th</sup> from our training set. For denoting the training example at the first row we just show (x, y) or at 4th position as (x<sup>4</sup>, y<sup>4</sup>) and so on...

## Feeding the data to an algorithm in order to predict new values

We have features(x) and targets(y). We give this data to the algorithm and it creates a function which gives us an **estimate** called ŷ (y-hat). ŷ (y-hat) is not the true output, but just an estimate based on the size of data that is given. The more the size of the data, the more accurate prediction of ŷ gets and at some point comes close to the true target value.

![Feeding the data showcase](./related%20images/Feeding.png)

Comparing to our above house price prediction example, in a linear regression model, only one input variable is used i.e. it is univariate. Therefore, the function will likely produce a line of the form f(x) = wx + b or y = wx + b (slope-line formula).

![Linear Function graph](./related%20images/Straight%20line.png)